{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from dataset import *\n",
    "from data_handler import *\n",
    "from embeddings import *\n",
    "from vector_store import *\n",
    "from RAG_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['ConvFinQA', 'FinQA', 'MultiHeritt', 'TATQA']\n"
     ]
    }
   ],
   "source": [
    "dataset_manager = FinanceRAGDataset(\"../data\")\n",
    "# List available datasets\n",
    "print(\"Available datasets:\", dataset_manager.list_datasets())\n",
    "\n",
    "# Load corpus and queries from a specific dataset\n",
    "# DATASET_NAME = \"ConvFinQA\"\n",
    "# corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = DataHandler(Tokenizer(AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")),\n",
    "                             Embedder(AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")))\n",
    "EMBEDDING_DIM = 384\n",
    "MODEL_INPUT_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvFinQA': {'ndcg': {'@5': 0.6203079672174378, '@10': 0.6482060685886607},\n",
       "  'recall': {'@5': 0.753968253968254, '@10': 0.8412698412698413}},\n",
       " 'FinQA': {'ndcg': {'@5': 0.5291651355233714, '@10': 0.565027020238846},\n",
       "  'recall': {'@5': 0.6453488372093024, '@10': 0.7587209302325582}},\n",
       " 'MultiHeritt': {'ndcg': {'@5': 0.35486964947430705,\n",
       "   '@10': 0.3808145154850899},\n",
       "  'recall': {'@5': 0.12278693528693527, '@10': 0.16019044691989898}},\n",
       " 'TATQA': {'ndcg': {'@5': 0.4767318924611678, '@10': 0.5105819003850763},\n",
       "  'recall': {'@5': 0.5903614457831325, '@10': 0.6927710843373494}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment without table embedding with LLM\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.embed_corpus(MODEL_INPUT_SIZE)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "    evaluation = pipeline.evaluate()\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvFinQA': {'ndcg': {'@5': 0.6936408876086481, '@10': 0.7198161662557143},\n",
       "  'recall': {'@5': 0.8174603174603174, '@10': 0.8968253968253969}},\n",
       " 'FinQA': {'ndcg': {'@5': 0.6128869038473453, '@10': 0.6418173092154987},\n",
       "  'recall': {'@5': 0.7238372093023255, '@10': 0.813953488372093}},\n",
       " 'MultiHeritt': {'ndcg': {'@5': 0.3839623199665212,\n",
       "   '@10': 0.41085262128752975},\n",
       "  'recall': {'@5': 0.1319805099770853, '@10': 0.1676716928429257}},\n",
       " 'TATQA': {'ndcg': {'@5': 0.5032479648916659, '@10': 0.5391244336550254},\n",
       "  'recall': {'@5': 0.6224899598393574, '@10': 0.7329317269076305}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with short table summary with LLM\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_short.npy')\n",
    "    pipeline.embed_corpus(MODEL_INPUT_SIZE)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "    evaluation = pipeline.evaluate()\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1801 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ConvFinQA': {'ndcg': {'@5': 0.7110419674913173, '@10': 0.7348281191886693},\n",
       "  'recall': {'@5': 0.8333333333333334, '@10': 0.9047619047619048}},\n",
       " 'FinQA': {'ndcg': {'@5': 0.6019617723665021, '@10': 0.6323604451900163},\n",
       "  'recall': {'@5': 0.7180232558139535, '@10': 0.813953488372093}},\n",
       " 'MultiHeritt': {'ndcg': {'@5': 0.3975642943217569, '@10': 0.4233684141461655},\n",
       "  'recall': {'@5': 0.13475536069714153, '@10': 0.1748048279726362}},\n",
       " 'TATQA': {'ndcg': {'@5': 0.5123626228747631, '@10': 0.5488969508922538},\n",
       "  'recall': {'@5': 0.6224899598393574, '@10': 0.7369477911646586}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with long table summary with LLM\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_long.npy')\n",
    "    pipeline.embed_corpus(MODEL_INPUT_SIZE)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "    evaluation = pipeline.evaluate()\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "experiment_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
