{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from dataset import *\n",
    "from data_handler import *\n",
    "from embeddings import *\n",
    "from vector_store import *\n",
    "from RAG_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['ConvFinQA', 'FinQA', 'MultiHeritt', 'TATQA']\n"
     ]
    }
   ],
   "source": [
    "dataset_manager = FinanceRAGDataset(\"../data\")\n",
    "# List available datasets\n",
    "print(\"Available datasets:\", dataset_manager.list_datasets())\n",
    "\n",
    "# Load corpus and queries from a specific dataset\n",
    "# DATASET_NAME = \"ConvFinQA\"\n",
    "# corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = DataHandler(Tokenizer(AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")),\n",
    "                             Embedder(AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")))\n",
    "EMBEDDING_DIM = 384\n",
    "MODEL_INPUT_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_processor = DataHandler(Tokenizer(AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")),\n",
    "#                              Embedder(AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")))\n",
    "# EMBEDDING_DIM = 768\n",
    "# MODEL_INPUT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column_metrics(df):\n",
    "    for metric in ['ndcg', 'recall', 'mrr']:\n",
    "        df[f'{metric}_5'] = df[metric].apply(lambda x: x['@5'])\n",
    "        df[f'{metric}_10'] = df[metric].apply(lambda x: x['@10'])\n",
    "        df.drop(metric, axis=1, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'dataset'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental removing the tables from the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt \tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA \tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>0.4744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.5116</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.4109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>0.2585</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.5161</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>0.3410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.5113   0.5286    0.6429     0.6984  0.4676  0.4744\n",
       "1        FinQA  0.4265   0.4579    0.5116     0.6105  0.3983  0.4109\n",
       "2  MultiHeritt  0.2308   0.2585    0.0828     0.1178  0.0529  0.0576\n",
       "3        TATQA  0.3594   0.3830    0.4438     0.5161  0.3312  0.3410"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment without tables (and without summarization) (_nt_ns: df_results_nt_ns)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.manage_corpus(chunk_size=MODEL_INPUT_SIZE, remove_tables=True)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "\n",
    "    best_chunks_nt_ns = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_nt_ns)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_nt_ns = pd.DataFrame(experiment_results).T\n",
    "# df_results_nt_ns['setting'] = 'NT_NS'\n",
    "df_results_nt_ns = split_column_metrics(df_results_nt_ns)\n",
    "df_results_nt_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m RAGPipeline(corpus, queries, qrels, text_processor)\n\u001b[0;32m      9\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mload_table_summaries(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/table_summaries_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_short.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanage_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_INPUT_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mpopulate_vector_store(EMBEDDING_DIM)\n\u001b[0;32m     12\u001b[0m pipeline\u001b[38;5;241m.\u001b[39membed_queries(MODEL_INPUT_SIZE)\n",
      "File \u001b[1;32mc:\\Users\\alece\\Desktop\\FinanceRag\\src\\RAG_pipeline.py:52\u001b[0m, in \u001b[0;36mRAGPipeline.manage_corpus\u001b[1;34m(self, chunk_size, method, remove_tables)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_tables:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_processor\u001b[38;5;241m.\u001b[39mremove_tables()\n\u001b[0;32m     51\u001b[0m embedded_doc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;241m.\u001b[39mget_data()\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embedding[idx] \u001b[38;5;241m=\u001b[39m embedded_doc\n",
      "File \u001b[1;32mc:\\Users\\alece\\Desktop\\FinanceRag\\src\\data_handler.py:93\u001b[0m, in \u001b[0;36mDataHandler.embed\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_model\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, method\u001b[38;5;241m=\u001b[39mmethod)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alece\\Desktop\\FinanceRag\\src\\embeddings.py:96\u001b[0m, in \u001b[0;36mEmbedder.encode\u001b[1;34m(self, chunks, method, batch_size)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m batch_chunks:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_single_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m         batch_embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\alece\\Desktop\\FinanceRag\\src\\embeddings.py:45\u001b[0m, in \u001b[0;36mEmbedder._generate_single_embedding\u001b[1;34m(self, chunk, method)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Compute model outputs\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 45\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Embedding extraction\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_layer\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;66;03m# CLS token from the last hidden layer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alece\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Experiment with short table summary with LLM without table text (_nt_ss: no table short summary)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_short.npy')\n",
    "    pipeline.manage_corpus(MODEL_INPUT_SIZE, remove_tables=True)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "\n",
    "    best_chunks_nt_ss = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_nt_ss)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_nt_ss = pd.DataFrame(experiment_results).T\n",
    "# df_results_nt_ss['setting'] = 'NT_SS'\n",
    "df_results_nt_ss = split_column_metrics(df_results_nt_ss)\n",
    "df_results_nt_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt \tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA \tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.5569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.4582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.7139   0.7297    0.8333     0.8810  0.6741  0.6809\n",
       "1        FinQA  0.5800   0.6093    0.6831     0.7762  0.5453  0.5569\n",
       "2  MultiHeritt  0.3283   0.3585    0.1144     0.1524  0.0768  0.0820\n",
       "3        TATQA  0.4789   0.5067    0.5763     0.6606  0.4463  0.4582"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with long table summary with LLM (_nt_ls: no table long summary)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_long.npy')\n",
    "    pipeline.manage_corpus(MODEL_INPUT_SIZE, remove_tables=True)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "\n",
    "    best_chunks_nt_ls = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_nt_ls)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_nt_ls = pd.DataFrame(experiment_results).T\n",
    "# df_results_nt_ls['setting'] = 'NT_LS'\n",
    "df_results_nt_ls = split_column_metrics(df_results_nt_ls)\n",
    "df_results_nt_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental keeping the tables in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA\tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA\tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt\tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA\tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.8413</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.5874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.5046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.3549</td>\n",
       "      <td>0.3808</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.5904</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.4537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.6203   0.6482    0.7540     0.8413  0.5761  0.5874\n",
       "1        FinQA  0.5292   0.5650    0.6453     0.7587  0.4903  0.5046\n",
       "2  MultiHeritt  0.3549   0.3808    0.1228     0.1602  0.0859  0.0908\n",
       "3        TATQA  0.4767   0.5106    0.5904     0.6928  0.4394  0.4537"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with text table but without table summaries with LLM (_ns: no summarization)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME}\\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.manage_corpus(chunk_size=MODEL_INPUT_SIZE)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "\n",
    "    best_chunks_ns = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_ns)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_ns = pd.DataFrame(experiment_results).T\n",
    "# df_results_ns['setting'] = 'NS'\n",
    "df_results_ns = split_column_metrics(df_results_ns)\n",
    "df_results_ns.to_excel(\"df_results_ns.xlsx\", index=False)\n",
    "df_results_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt \tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA \tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.7198</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.6631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.6129</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>0.5757</td>\n",
       "      <td>0.5876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.0966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.5032</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.4782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.6936   0.7198    0.8175     0.8968  0.6520  0.6631\n",
       "1        FinQA  0.6129   0.6418    0.7238     0.8140  0.5757  0.5876\n",
       "2  MultiHeritt  0.3840   0.4109    0.1320     0.1677  0.0919  0.0966\n",
       "3        TATQA  0.5032   0.5391    0.6225     0.7329  0.4633  0.4782"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with short table summary with LLM (_ss: short summary)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_short.npy')\n",
    "    pipeline.manage_corpus(MODEL_INPUT_SIZE, remove_tables=False)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "\n",
    "    best_chunks_ss = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_ss)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_ss = pd.DataFrame(experiment_results).T\n",
    "# df_results_ss['setting'] = 'SS'\n",
    "df_results_ss = split_column_metrics(df_results_ss)\n",
    "df_results_ss.to_excel(\"df_results_ss.xlsx\", index=False)\n",
    "df_results_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt \tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA \tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.7348</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.6801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.6020</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>0.5752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.4234</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>0.4758</td>\n",
       "      <td>0.4906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.7110   0.7348    0.8333     0.9048  0.6698  0.6801\n",
       "1        FinQA  0.6020   0.6324    0.7180     0.8140  0.5630  0.5752\n",
       "2  MultiHeritt  0.3976   0.4234    0.1348     0.1748  0.0965  0.1017\n",
       "3        TATQA  0.5124   0.5489    0.6225     0.7369  0.4758  0.4906"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with long table summary with LLM (_ls: long summary)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_long.npy')\n",
    "    pipeline.manage_corpus(MODEL_INPUT_SIZE, remove_tables=False)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE)\n",
    "\n",
    "    best_chunks_ls = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_ls)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_ls = pd.DataFrame(experiment_results).T\n",
    "# df_results_ls['setting'] = 'LS'\n",
    "df_results_ls = split_column_metrics(df_results_ls)\n",
    "df_results_ls.to_excel(\"df_results_ls.xlsx\", index=False)\n",
    "df_results_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt \tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA \tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.7134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.5760</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.7936</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.5509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.4259</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.4935</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.4731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.7445   0.7554    0.8492     0.8810  0.7086  0.7134\n",
       "1        FinQA  0.5760   0.6088    0.6919     0.7936  0.5374  0.5509\n",
       "2  MultiHeritt  0.4067   0.4259    0.1384     0.1696  0.0987  0.1030\n",
       "3        TATQA  0.4935   0.5302    0.6004     0.7149  0.4582  0.4731"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with query expansion rephrase and long table summary with LLM (qer_ls: long summary)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_long.npy')\n",
    "    pipeline.load_query_expansion(f'../data/{DATASET_NAME}/queries_expanded_{DATASET_NAME}_Q2D.npy', 10)\n",
    "    pipeline.manage_corpus(MODEL_INPUT_SIZE, remove_tables=False)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE, mode='trunk')\n",
    "\n",
    "    best_chunks_ls = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_ls)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_ls = pd.DataFrame(experiment_results).T\n",
    "# df_results_ls['setting'] = 'LS'\n",
    "df_results_ls = split_column_metrics(df_results_ls)\n",
    "df_results_ls.to_excel(\"df_results_ls.xlsx\", index=False)\n",
    "df_results_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ConvFinQA \tNumber of queries: 126 and Number of documents: 101\n",
      "\tFinished evaluation!\n",
      "Dataset: FinQA \tNumber of queries: 344 and Number of documents: 247\n",
      "\tFinished evaluation!\n",
      "Dataset: MultiHeritt \tNumber of queries: 292 and Number of documents: 876\n",
      "\tFinished evaluation!\n",
      "Dataset: TATQA \tNumber of queries: 498 and Number of documents: 248\n",
      "\tFinished evaluation!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ndcg_5</th>\n",
       "      <th>ndcg_10</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>mrr_5</th>\n",
       "      <th>mrr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvFinQA</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinQA</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.5989</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>0.5437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultiHeritt</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.0996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATQA</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.5099</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.4494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  ndcg_5  ndcg_10  recall_5  recall_10   mrr_5  mrr_10\n",
       "0    ConvFinQA  0.7226   0.7412    0.8175     0.8730  0.6901  0.6982\n",
       "1        FinQA  0.5666   0.5989    0.6744     0.7762  0.5308  0.5437\n",
       "2  MultiHeritt  0.3864   0.4142    0.1331     0.1733  0.0942  0.0996\n",
       "3        TATQA  0.4746   0.5099    0.5944     0.7048  0.4350  0.4494"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with query expansion rephrase and long table summary with LLM (qer_ls: long summary)\n",
    "experiment_results = {}\n",
    "for DATASET_NAME in dataset_manager.list_datasets():\n",
    "    corpus, queries, qrels = dataset_manager.load_dataset(DATASET_NAME)\n",
    "    corpus, queries = reduce_dataset_size(corpus, queries, qrels)\n",
    "    print(f\"Dataset: {DATASET_NAME} \\tNumber of queries: {len(queries)} and Number of documents: {len(corpus)}\")\n",
    "\n",
    "    pipeline = RAGPipeline(corpus, queries, qrels, text_processor)\n",
    "    pipeline.load_table_summaries(f'../data/{DATASET_NAME}/table_summaries_{DATASET_NAME}_long.npy')\n",
    "    pipeline.load_query_expansion(f'../data/{DATASET_NAME}/queries_expanded_{DATASET_NAME}_Q2D.npy', 10)\n",
    "    pipeline.manage_corpus(MODEL_INPUT_SIZE, remove_tables=False)\n",
    "    pipeline.populate_vector_store(EMBEDDING_DIM)\n",
    "    pipeline.embed_queries(MODEL_INPUT_SIZE, mode='trunk')\n",
    "\n",
    "    best_chunks_ls = pipeline.retrieve()\n",
    "    evaluation = pipeline.evaluate(best_chunks_ls)\n",
    "    experiment_results[DATASET_NAME] = evaluation\n",
    "    print(\"\\tFinished evaluation!\")\n",
    "df_results_ls = pd.DataFrame(experiment_results).T\n",
    "# df_results_ls['setting'] = 'LS'\n",
    "df_results_ls = split_column_metrics(df_results_ls)\n",
    "df_results_ls.to_excel(\"df_results_ls.xlsx\", index=False)\n",
    "df_results_ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
